{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from dateutil.parser import parse\n",
    "from datetime import timedelta\n",
    "\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def import_data(filename):\n",
    "\treturn pd.read_csv(filename, header=0, sep = '\\t').fillna('').values\n",
    "\n",
    "\n",
    "def pre_process(data):\n",
    "\treturn data\n",
    "\n",
    "\n",
    "def add_sentiment(data):\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    avgs = np.empty((len(data),1))\n",
    "    print(len(data))\n",
    "    for i in range(0,len(data)):\n",
    "        field = data[i][8]\n",
    "        avgs[i] = sid.polarity_scores(field)['compound']\n",
    "    return np.append(data, avgs, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_avg_sentiments(data):\n",
    "\tpreviousDate = parse(data[0,8]) - timedelta(days=1)\n",
    "\tpreviousMs = -1\n",
    "\tpreviousMsTom = -1\n",
    "\ttempSents = [0]\n",
    "\toutput = np.empty((1,3))\n",
    "\tfor line in data:\n",
    "\t\tdate = parse(line[8])\n",
    "\t\tsentiment = line[12]\n",
    "\t\tms = line[9]\n",
    "\t\tmsTom = line[10]\n",
    "\t\tif date > previousDate:\n",
    "\t\t\tavgSent = sum(tempSents)/len(tempSents)\n",
    "\t\t\toutput = np.append(output,[[ms, msTom, avgSent]], axis=0)\n",
    "\n",
    "\t\t\ttempSents = []\n",
    "\t\t\ttempSents.append(sentiment)\n",
    "\t\t\tpreviousDate = date\n",
    "\t\t\tpreviousMs = ms\n",
    "\t\t\tpreviousMsTom = msTom\n",
    "\t\telif date == previousDate:\n",
    "\t\t\ttempSents.append(sentiment)\n",
    "\t\telse:\n",
    "\t\t\tprint(\"Wrong date order.\")\n",
    "\treturn output[1:]\t# First row was to initialize. Ugly, but works.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(data):\n",
    "\toutput = np.empty((1,3))\n",
    "\tfor line in data:\n",
    "\t\tms = line[6]\n",
    "\t\tmsTom = line[7]\n",
    "\t\t#print(line[9])\n",
    "\t\tsentiment = line[9]\n",
    "\n",
    "\t\toutput = np.append(output, [[ms, msTom, sentiment]], axis=0)\n",
    "\treturn output[1:]\n",
    "\n",
    "\n",
    "def divide_train_test(data):\n",
    "\trandom.seed(2)\n",
    "\trandom.shuffle(data)\n",
    "\n",
    "\tsplit = .7 * len(data)\n",
    "\ttrain = data[:int(split)]\n",
    "\ttest = data[int(split):]\n",
    "\treturn train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, labels):\n",
    "\treturn svm.SVC(kernel='linear', C=1).fit(data, labels)\n",
    "\n",
    "\n",
    "def cross_validate(data, labels, clsfr):\n",
    "\treturn cross_val_score(clsfr, data, labels, cv=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_to_search = \"2019-09-12\"\n",
    "def Get_sentiment_results(date_to_search):\n",
    "    test_specific_date_sent = []\n",
    "    tweets_caused = []\n",
    "    data = import_data(\"combined_amazon_news_stocks.csv\")\n",
    "    #print(data)\n",
    "    pre_processed = pre_process(data)\n",
    "    sentiment_included = add_sentiment(pre_processed)\n",
    "    #print(sentiment_included)\n",
    "    for j in range(0,len(sentiment_included)):\n",
    "        date = sentiment_included[j][2]\n",
    "        if(date_to_search == date):\n",
    "            sentiment = sentiment_included[j][9]\n",
    "            tweets_cause = sentiment_included[j][8]\n",
    "            if tweets_cause not in tweets_caused:\n",
    "                tweets_caused.append(tweets_cause)            \n",
    "            test_specific_date_sent.append(sentiment)\n",
    "    \n",
    "    test_date_sentiments = np.array([test_specific_date_sent]).reshape(len(test_specific_date_sent),1)\n",
    "    #print(np.array([test_specific_date_sent]).reshape(len(test_specific_date_sent),1))\n",
    "    \n",
    "    #print(len(sentiment_included))\n",
    "    avg_sentiments = filter_data(sentiment_included)\n",
    "\n",
    "    print(\"Data exists of \" + str(avg_sentiments.shape[0]) + \" cases.\\n\")\n",
    "\n",
    "    # Predict today's stock\n",
    "    train_set, test_set = divide_train_test(avg_sentiments)\n",
    "\n",
    "    \n",
    "    train_labels = train_set[:,0].ravel()\n",
    "    train_sentiments = train_set[:,2].reshape(len(train_set), 1)\n",
    "    test_labels = test_set[:,0].ravel()\n",
    "    #print(\"test_labels::\")\n",
    "    #print(test_labels)\n",
    "    test_sentiments = test_set[:,2].reshape(len(test_set),1)\n",
    "    clsfr = train(train_sentiments, train_labels.astype('int'))\n",
    "    print(\"Training done.\")\n",
    "    print(\"Pedicting today's stock...\")\n",
    "    #print(test_sentiments)\n",
    "    scores = cross_validate(test_sentiments, test_labels.astype('int'), clsfr)\n",
    "    #print(scores)\n",
    "    #print(test_labels)\n",
    "    #print(clsfr.predict(test_sentiments))\n",
    "    print(\"Average: \" + str(scores.mean()))\n",
    "    print(\"Cross validation done.\\n\")\n",
    "    \n",
    "    print(\"Prediction for specific date!!!\")\n",
    "    \n",
    "    pred_arr = clsfr.predict(test_date_sentiments)\n",
    "    #print(test_date_sentiments)\n",
    "    print(\"Average score for date:\"+ str(pred_arr.mean()))\n",
    "    if(pred_arr.mean() > 0.5):\n",
    "        final_result = \"Price is going to increasee!\"\n",
    "        print(\"Price is going to increasee!\")\n",
    "    else:\n",
    "        final_result = \"Price is going to decrease!\"\n",
    "        print(\"Price is going to decrease!\")\n",
    "    return final_result, tweets_caused\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    # Predict tomorrow's stock\n",
    "#     train_set, test_set = divide_train_test(avg_sentiments)\n",
    "#     train_labels = train_set[:,1].ravel()\n",
    "#     train_sentiments = train_set[:,].reshape(len(train_set), 1)\n",
    "#     test_labels = test_set[:,1].ravel()\n",
    "#     test_sentiments = test_set[:,].reshape(len(test_set),1)\n",
    "\n",
    "#     clsfr = train(train_sentiments, train_labels.astype('int'))\n",
    "#     print(\"Training done.\")\n",
    "#     print(\"Predicting tomorrow's stock...\")\n",
    "# \tscores = cross_validate(test_sentiments, test_labels.astype('int'), clsfr)\n",
    "# \tprint(scores)\n",
    "# \tprint(\"Average: \" + str(scores.mean()))\n",
    "# \tprint(\"Cross validation done.\\n\")\n",
    "# \t# Predict the day after tomorrow's stock\n",
    "# \ttrain_set, test_set = divide_train_test(avg_sentiments)\n",
    "# \ttrain_labels = train_set[:,2].ravel()\n",
    "# \ttrain_sentiments = train_set[:,3].reshape(len(train_set), 1)\n",
    "# \ttest_labels = test_set[:,2].ravel()\n",
    "# \ttest_sentiments = test_set[:,3].reshape(len(test_set),1)\n",
    "\n",
    "# \tclsfr = train(train_sentiments, train_labels.astype('int'))\n",
    "# \tprint(\"Training done.\")\n",
    "# \tprint(\"Predicting the day after tomorrow's stock...\")\n",
    "# \tscores = cross_validate(test_sentiments, test_labels.astype('int'), clsfr)\n",
    "# \tprint(scores)\n",
    "# \tprint(\"Average: \" + str(scores.mean()))\n",
    "# \tprint(\"Cross validation done.\")\n",
    "# \tprint(\"Done.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164\n",
      "Data exists of 164 cases.\n",
      "\n",
      "Training done.\n",
      "Pedicting today's stock...\n",
      "Average: 0.6\n",
      "Cross validation done.\n",
      "\n",
      "Prediction for specific date!!!\n",
      "Average score for date:1.0\n",
      "Price is going to increasee!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Price is going to increasee!',\n",
       " [\"alysfight thanks for reaching out and sharing we're always happy to help raise awareness for such a worthy cause amazongoesgold\",\n",
       "  \"yesihave4kids that's purrrfect when your feline isn't snuggled up or hanging out in amazon boxes, what does this darling kitty like to do?\",\n",
       "  'rt verge: amazon videos animated series undone could be the start of something amazing https:t.coulwyzf74dw https:t.coea9klxiqqe',\n",
       "  \"rt indiewire: amazon's undone is a genre-bending, time-breaking experiment and an artistic feat. benttravers reviews: https:t.colip7x\",\n",
       "  'take an exclusive look inside thegoldfinch movie before it hits theaters tomorrow. watch the film on amazon prime https:t.cojzsd3zezti',\n",
       "  'rt nycomiccon: amazon primevideo takeover featuring tom clancys jackryanamazon and expanseonprime. sat, 10.5  10:45 am  main stage',\n",
       "  'amazons crowdsourced qamp;a community alexa answers goes live for all https:t.coj35bqbnoug by sarahintampa https:t.co3l6q8drtpe',\n",
       "  'amazon, facebook, apple, google, and microsoft skip out on a letter asking the senate to enact stronger gun laws https:t.coq1csgcqco9',\n",
       "  'rt benfoxrubin: amazon just sent out invites for a devices and services event for wednesday, sept. 25.',\n",
       "  'shopify overtakes ebay as second biggest shopping site after amazon https:t.comhbjqnev4x https:t.cos0omztse20',\n",
       "  'amazon will launch new alexa hardware on september 25 https:t.coe1zboualtv',\n",
       "  'amazon videos animated series undone could be the start of something amazing https:t.coulwyzf74dw https:t.coea9klxiqqe',\n",
       "  'amazon announces hardware event on september 25th https:t.co5ee7eevb24 https:t.cokezgl9lgru',\n",
       "  'amazon opens up its crowdsourced alexa answers program to anyone https:t.coljeidnflz8 https:t.cofv9p6f2gvh',\n",
       "  'need a laptop for school? this acer aspire e 15 is discounted by 70 on amazon https:t.coeft57iu5tn',\n",
       "  'score the new microsoft surface go tablet pc for 499 on amazon https:t.coht8wdzepwm'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Get_sentiment_results(date_to_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
